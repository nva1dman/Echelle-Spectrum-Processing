{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a483c8b-a4b6-45fd-8f13-e2e8b214819d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objname\n",
      "objfile\n",
      "all3.cl\n",
      "zerocomb_ccdproc_tco.cl\n",
      "apall_tco.cl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nadezhda/anaconda3/lib/python3.11/site-packages/astroquery/simbad/core.py:135: UserWarning: Warning: The script line number 3 raised an error (recorded in the `errors` attribute of the result table): 'IotPsc': No known catalog could be found\n",
      "  warnings.warn(\"Warning: The script line number %i raised \"\n",
      "/Users/nadezhda/anaconda3/lib/python3.11/site-packages/astroquery/simbad/core.py:135: UserWarning: Warning: The script line number 3 raised an error (recorded in the `errors` attribute of the result table): 'GamCas' this identifier has an incorrect format for catalog: \tG : Giclas\n",
      "  warnings.warn(\"Warning: The script line number %i raised \"\n",
      "/Users/nadezhda/anaconda3/lib/python3.11/site-packages/astroquery/simbad/core.py:135: UserWarning: Warning: The script line number 3 raised an error (recorded in the `errors` attribute of the result table): 'PhiAnd': No known catalog could be found\n",
      "  warnings.warn(\"Warning: The script line number %i raised \"\n",
      "/Users/nadezhda/anaconda3/lib/python3.11/site-packages/astroquery/simbad/core.py:135: UserWarning: Warning: The script line number 3 raised an error (recorded in the `errors` attribute of the result table): 'AlpUMi' this identifier has an incorrect format for catalog: \tA (ACO): Abell, Corwin, Olowin\n",
      "  warnings.warn(\"Warning: The script line number %i raised \"\n",
      "/Users/nadezhda/anaconda3/lib/python3.11/site-packages/astroquery/simbad/core.py:135: UserWarning: Warning: The script line number 3 raised an error (recorded in the `errors` attribute of the result table): 'QYGem': No known catalog could be found\n",
      "  warnings.warn(\"Warning: The script line number %i raised \"\n",
      "/Users/nadezhda/anaconda3/lib/python3.11/site-packages/astroquery/simbad/core.py:135: UserWarning: Warning: The script line number 3 raised an error (recorded in the `errors` attribute of the result table): 'FSCMa': No known catalog could be found\n",
      "  warnings.warn(\"Warning: The script line number %i raised \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scombine.cl\n",
      "comp1\n",
      "comp2\n",
      "comp3\n",
      "comp4\n",
      "imcomb.cl\n",
      "apall_comp.cl\n",
      "ut.cl\n",
      "thar.cl\n",
      "obj.nowav\n",
      "obj.wav\n",
      "Обработка завершена.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "from astroquery.simbad import Simbad\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "\n",
    "# Список объектов из журнала наблюдений\n",
    "raw_objects = \"\"\"\n",
    "Iot Psc\n",
    "Gam Cas\n",
    "Phi And\n",
    "BS 1040\n",
    "Pleione\n",
    "BS 1389\n",
    "BS 1728\n",
    "BS 1752\n",
    "Alp UMi\n",
    "QY Gem\n",
    "FS CMa\n",
    "HD 50138\n",
    "3 Pup\n",
    "HD 52961\n",
    "HD 74721\n",
    "\"\"\"\n",
    "\n",
    "# Преобразование списка объектов\n",
    "objects = [obj.strip().replace(\" \", \"\") for obj in raw_objects.strip().split('\\n')]\n",
    "\n",
    "# Путь к директории для сохранения файлов\n",
    "directory_path = '/Users/nadezhda/Documents/TCO_spectra/20240121'\n",
    "\n",
    "# Вспомогательные функции\n",
    "def extract_date_from_filename(directory_path):\n",
    "    for filename in os.listdir(directory_path):\n",
    "        match = re.match(r\"(\\d{8})-\\d{6}-.*\\.fit\", filename)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return None\n",
    "\n",
    "def get_object_name(filename):\n",
    "    parts = filename.split('-')\n",
    "    return parts[2] if len(parts) > 2 else filename\n",
    "\n",
    "# Получение даты наблюдений из названий файлов\n",
    "observation_date = extract_date_from_filename(directory_path)\n",
    "\n",
    "if observation_date is None:\n",
    "    raise ValueError(\"Не удалось извлечь дату наблюдений из названий файлов.\")\n",
    "\n",
    "# Уменьшение даты на один день\n",
    "observation_date = (datetime.strptime(observation_date, '%Y%m%d') - timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "# Создание и запись файла objname\n",
    "objname_path = os.path.join(directory_path, \"objname\")\n",
    "with open(objname_path, 'w') as objname_file:\n",
    "    for obj in objects:\n",
    "        objname_file.write(f\"hedit\\t*{obj}*\\tOBJNAME\\t{obj}\\n\")\n",
    "print(\"objname\")\n",
    "\n",
    "# Создание и запись файла objfile\n",
    "objfile_path = os.path.join(directory_path, \"objfile\")\n",
    "with open(objfile_path, 'w') as objfile:\n",
    "    for obj in objects:\n",
    "        objfile.write(f\"ls\\t*{obj}*\\t>\\t{obj.lower()}\\n\")\n",
    "print(\"objfile\")\n",
    "\n",
    "# Создание строки для команды ls\n",
    "ls_command = \"ls \" + \" \".join([f\"*{obj}*\" for obj in objects]) + \" > obj\"\n",
    "\n",
    "# Содержимое файла all3.cl\n",
    "all3_cl_content = f\"\"\"\n",
    "string *list2\n",
    "string s4,s5\n",
    "\n",
    "ls *BIAS* > zero\n",
    "\n",
    "ls *THAR* > comp\n",
    "\n",
    "ls *FLAT* > flat\n",
    "\n",
    "{ls_command}\n",
    "\n",
    "hedit (\"@zero\",\n",
    "\"IMAGETYP\", \"zero\", add=yes, delete=no, verify=no, show=yes, update=yes)\n",
    "\n",
    "hedit (\"@comp\",\n",
    "\"IMAGETYP\", \"comp\", add=yes, delete=no, verify=no, show=yes, update=yes)\n",
    "\n",
    "hedit (\"@flat\",\n",
    "\"IMAGETYP\", \"flat\", add=yes, delete=no, verify=no, show=yes, update=yes)\n",
    "\n",
    "hedit (\"@obj\",\n",
    "\"IMAGETYP\", \"object\", add=yes, delete=no, verify=no, show=yes, update=yes)\n",
    "\n",
    "hsel (\"@obj\",\n",
    "\"$I,EXPOSURE\", \"yes\", >> \"imglist\")\n",
    "\n",
    "list=\"imglist\" \n",
    "while (fscan (list, s1, x, y) != EOF) \n",
    "{{\n",
    "hedit (s1,\n",
    "\"EXPTIME\", x, add=yes, delete=no, verify=no, show=yes, update=yes)\n",
    "}}\n",
    "del imglist\n",
    "\n",
    "hedit (\"@comp\",\n",
    "\"DISPAXIS\", \"1\", add=yes, delete=no, verify=no, show=yes, update=yes)\n",
    "\n",
    "hedit (\"@flat\",\n",
    "\"DISPAXIS\", \"1\", add=yes, delete=no, verify=no, show=yes, update=yes)\n",
    "\n",
    "hedit (\"@obj\",\n",
    "\"DISPAXIS\", \"1\", add=yes, delete=no, verify=no, show=yes, update=yes)\n",
    "\n",
    "hsel (\"@obj\",\n",
    "\"$I,OBJNAME\", \"yes\", >> \"imglist\")\n",
    "\n",
    "list=\"imglist\" \n",
    "while (fscan (list, s1, s2) != EOF) \n",
    "{{\n",
    "list2=\"coord_tco.txt\"\n",
    "while (fscan (list2, s3, s4, s5) != EOF) \n",
    "{{\n",
    "if (s2==s3)\n",
    "{{\n",
    "print (s1,\" find\")\n",
    "hedit (s1,\n",
    "\"RA\", s4, add=yes, delete=no, verify=no, show=no, update=yes)\n",
    "hedit (s1,\n",
    "\"DEC\", s5, add=yes, delete=no, verify=no, show=no, update=yes)\n",
    "hedit (s1,\n",
    "\"EPOCH\", \"2000\", add=yes, delete=no, verify=no, show=no, update=yes)\n",
    "hedit (s1,\n",
    "\"OBSERVAT\", \"tco\", add=yes, delete=no, verify=no, show=no, update=yes)\n",
    "}}\n",
    "else\n",
    "x=1\n",
    "}}\n",
    "}}\n",
    "del imglist\n",
    "\n",
    "print (\" \")\n",
    "print (\"Check New Keywords\")\n",
    "print (\" \")\n",
    "\n",
    "hsel (\"@obj\",\n",
    "\"$I,RA,DEC,EPOCH,IMAGETYP,DISPAXIS,OBSERVAT\", \"yes\")\n",
    "\"\"\"\n",
    "\n",
    "# Путь к директории для сохранения файла all3.cl\n",
    "all3_cl_path = os.path.join(directory_path, \"all3.cl\")\n",
    "\n",
    "# Запись содержимого в файл all3.cl\n",
    "with open(all3_cl_path, 'w') as all3_cl_file:\n",
    "    all3_cl_file.write(all3_cl_content)\n",
    "\n",
    "print(\"all3.cl\")\n",
    "\n",
    "# Содержимое файла zerocomb_ccdproc_tco.cl\n",
    "zerocomb_ccdproc_tco_cl_content = f\"\"\"\n",
    "zerocombine (\"@zero\", output=\"zero_{observation_date}\", combine=\"average\", reject=\"minmax\", ccdtype=\"zero\",\n",
    "process=no, delete=no, clobber=no, scale=\"none\", statsec=\"\", nlow=0, nhigh=1,\n",
    "nkeep=1, mclip=yes, lsigma=3., hsigma=3., rdnoise=\"5.\", gain=\"0.26\",\n",
    "snoise=\"0.\", pclip=-0.5, blank=0.)\n",
    "\n",
    "ccdproc (\"@comp\",\n",
    "output=\"b@comp\", ccdtype=\"comp\", max_cache=34, noproc=no, fixpix=yes,\n",
    "overscan=no, trim=no, zerocor=yes, darkcor=no, flatcor=no, illumcor=no,\n",
    "fringecor=no, readcor=no, scancor=no, readaxis=\"line\", fixfile=\"badpix_atik_20231221\",\n",
    "biassec=\"\", trimsec=\"\", zero=\"zero_{observation_date}\", dark=\"\", flat=\"\", illum=\"\",\n",
    "fringe=\"\", minreplace=1., scantype=\"shortscan\", nscan=1, interactive=no,\n",
    "function=\"legendre\", order=1, sample=\"*\", naverage=1, niterate=1,\n",
    "low_reject=3., high_reject=3., grow=0.)\n",
    "\n",
    "ccdproc (\"@obj\",\n",
    "output=\"b@obj\", ccdtype=\"object\", max_cache=34, noproc=no, fixpix=yes,\n",
    "overscan=no, trim=no, zerocor=yes, darkcor=no, flatcor=no, illumcor=no,\n",
    "fringecor=no, readcor=no, scancor=no, readaxis=\"line\", fixfile=\"badpix_atik_20231221\",\n",
    "biassec=\"\", trimsec=\"\", zero=\"zero_{observation_date}\", dark=\"\", flat=\"\", illum=\"\",\n",
    "fringe=\"\", minreplace=1., scantype=\"shortscan\", nscan=1, interactive=no,\n",
    "function=\"legendre\", order=1, sample=\"*\", naverage=1, niterate=1,\n",
    "low_reject=3., high_reject=3., grow=0.)\n",
    "\n",
    "del comp\n",
    "\n",
    "ls b*THAR* > comp\n",
    "\"\"\"\n",
    "\n",
    "# Путь к директории для сохранения файла zerocomb_ccdproc_tco.cl\n",
    "zerocomb_ccdproc_tco_cl_path = os.path.join(directory_path, \"zerocomb_ccdproc_tco.cl\")\n",
    "\n",
    "# Запись содержимого в файл zerocomb_ccdproc_tco.cl\n",
    "with open(zerocomb_ccdproc_tco_cl_path, 'w') as zerocomb_ccdproc_tco_cl_file:\n",
    "    zerocomb_ccdproc_tco_cl_file.write(zerocomb_ccdproc_tco_cl_content)\n",
    "\n",
    "print(\"zerocomb_ccdproc_tco.cl\")\n",
    "\n",
    "# Создание и запись файла apall_commands\n",
    "apall_commands_path = os.path.join(directory_path, \"apall_tco.cl\")\n",
    "\n",
    "def get_brightest_star(objects):\n",
    "    custom_simbad = Simbad()\n",
    "    custom_simbad.add_votable_fields(\"flux(V)\")\n",
    "    brightest_star = None\n",
    "    max_flux = float('inf')\n",
    "    for obj in objects:\n",
    "        result = custom_simbad.query_object(obj)\n",
    "        if result is not None and result['FLUX_V'][0] < max_flux:\n",
    "            max_flux = result['FLUX_V'][0]\n",
    "            brightest_star = obj\n",
    "    return brightest_star\n",
    "\n",
    "brightest_star = get_brightest_star(objects)\n",
    "\n",
    "if brightest_star is None:\n",
    "    raise ValueError(\"Не удалось определить самую яркую звезду.\")\n",
    "\n",
    "objects.remove(brightest_star)\n",
    "objects.insert(0, brightest_star)\n",
    "\n",
    "with open(apall_commands_path, 'w') as apall_commands:\n",
    "    for i, obj in enumerate(objects):\n",
    "        suffix = \"1\" if i == 0 else \"\"\n",
    "        apall_commands.write(f\"apall (\\\"@{obj.lower()}\\\",0, output=\\\"a@{obj.lower()}{suffix}\\\", apertures=\\\"\\\", format=\\\"echelle\\\",references=\\\"last\\\", profiles=\\\"\\\", interactive=no,find=no, recenter=yes,resize=no, edit=no, trace=yes, fittrace=no,extract=yes, extras=no, review=no, line=INDEF, nsum=10, lower=-5., upper=5.,apidtable=\\\"\\\", b_function=\\\"chebyshev\\\", b_order=2, b_sample=\\\"-10:-6,6:10\\\",b_naverage=-3, b_niterate=0, b_low_reject=3., b_high_rejec=3., b_grow=0.,width=5., radius=10., threshold=0., minsep=5., maxsep=100000.,order=\\\"increasing\\\", aprecenter=\\\"\\\", npeaks=INDEF, shift=no, llimit=INDEF,ulimit=INDEF, ylevel=0.1, peak=yes, bkg=yes, r_grow=0., avglimits=no,t_nsum=10, t_step=3, t_nlost=3, t_function=\\\"legendre\\\", t_order=4,t_sample=\\\"*\\\", t_naverage=1, t_niterate=10, t_low_reject=3., t_high_rejec=3.,t_grow=0., background=\\\"median\\\", skybox=1, weights=\\\"none\\\", pfit=\\\"fit1d\\\",clean=no, saturation=INDEF, readnoise=\\\"5.\\\", gain=\\\"0.26\\\", lsigma=4., usigma=4.,nsubaps=1)\\n\")\n",
    "\n",
    "print(\"apall_tco.cl\")\n",
    "\n",
    "# Обработка передержанной линии Ha\n",
    "def get_ha_saturation_status(directory_path, x_coord=329, y_coord=873, x_range=50, y_range=50, threshold=65000):\n",
    "    files_by_object = defaultdict(list)\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.fit') and 'THAR' not in filename and 'BIAS' not in filename:\n",
    "            object_name = get_object_name(filename)\n",
    "            files_by_object[object_name].append(filename)\n",
    "\n",
    "    ha_status = {}\n",
    "    for object_name, files in files_by_object.items():\n",
    "        has_saturated = False\n",
    "        saturated_exposures = []\n",
    "        normal_exposures = []\n",
    "        for filename in files:\n",
    "            try:\n",
    "                filepath = os.path.join(directory_path, filename)\n",
    "                hdu = fits.open(filepath)\n",
    "                data = hdu[0].data\n",
    "\n",
    "                if data is None:\n",
    "                    continue\n",
    "\n",
    "                x_start = max(x_coord - x_range // 2, 0)\n",
    "                x_end = min(x_coord + x_range // 2, data.shape[1])\n",
    "                y_start = max(y_coord - y_range // 2, 0)\n",
    "                y_end = min(y_coord + y_range // 2, data.shape[0])\n",
    "\n",
    "                region = data[y_start:y_end, x_start:x_end]\n",
    "                max_value = np.max(region)\n",
    "\n",
    "                match = re.match(r'^\\d{8}-\\d{6}-.*-(\\d+)s-\\d+.fit$', filename)\n",
    "                if match:\n",
    "                    exposure = int(match.group(1))\n",
    "                    if max_value > threshold:\n",
    "                        has_saturated = True\n",
    "                        saturated_exposures.append(exposure)\n",
    "                    else:\n",
    "                        normal_exposures.append(exposure)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при обработке файла {filename}: {e}\")\n",
    "\n",
    "        ha_status[object_name] = {\n",
    "            'has_saturated': has_saturated,\n",
    "            'saturated_exposures': saturated_exposures,\n",
    "            'normal_exposures': normal_exposures\n",
    "        }\n",
    "\n",
    "    return ha_status\n",
    "\n",
    "ha_saturation_status = get_ha_saturation_status(directory_path)\n",
    "\n",
    "# Создание и запись файла scombine.cl\n",
    "scombine_path = os.path.join(directory_path, \"scombine.cl\")\n",
    "with open(scombine_path, 'w') as scombine_file:\n",
    "    for obj in objects:\n",
    "        status = ha_saturation_status.get(obj, {'has_saturated': False})\n",
    "        if status['has_saturated']:\n",
    "            # Записываем все экспозиции для lo\n",
    "            scombine_file.write(f\"scombine\\tab*{obj}*\\t{obj}_{observation_date}lo_nf\\n\")\n",
    "            # Записываем нормальные экспозиции для sh\n",
    "            sh_exposures = \",\".join([f\"ab*{obj}*{exp}s*\" for exp in status['normal_exposures']])\n",
    "            if sh_exposures:\n",
    "                scombine_file.write(f\"scombine\\t{sh_exposures}\\t{obj}_{observation_date}sh_nf\\n\")\n",
    "        else:\n",
    "            scombine_file.write(f\"scombine\\tab*{obj}*\\t{obj}_{observation_date}nf\\n\")\n",
    "\n",
    "print(\"scombine.cl\")\n",
    "\n",
    "# Создание и запись файлов compX и imcomb.cl\n",
    "def create_comp_and_imcomb_files(directory_path):\n",
    "    comp_files = {}\n",
    "    imcomb_lines = []\n",
    "    apall_lines = []\n",
    "    thar_files = sorted([f for f in os.listdir(directory_path) if \"THAR\" in f])\n",
    "    group_num = 1\n",
    "    for i in range(0, len(thar_files), 5):\n",
    "        comp_group = thar_files[i:i + 5]\n",
    "        if not comp_group:\n",
    "            break\n",
    "        comp_filename = f\"comp{group_num}\"\n",
    "        comp_files[comp_filename] = comp_group\n",
    "        imcomb_lines.append(f\"imcombine @{comp_filename} b{observation_date}-comp{group_num}-15s-1\")\n",
    "        apall_lines.append(f\"\"\"apall (\"b{observation_date}-comp{group_num}-15s-1\",\n",
    "0, output=\"eb{observation_date}-comp{group_num}-15s-1\", apertures=\"\", format=\"echelle\",\n",
    "references=\"last\", profiles=\"\", interactive=no,\n",
    "find=no, recenter=no, resize=no, edit=no, trace=yes, fittrace=no,\n",
    "extract=yes, extras=no, review=no, line=INDEF, nsum=10, lower=-5., upper=5.,\n",
    "apidtable=\"\", b_function=\"chebyshev\", b_order=2, b_sample=\"-10:-6,6:10\",\n",
    "b_naverage=-3, b_niterate=0, b_low_reject=3., b_high_rejec=3., b_grow=0.,\n",
    "width=5., radius=10., threshold=0., minsep=5., maxsep=100000.,\n",
    "order=\"increasing\", aprecenter=\"\", npeaks=INDEF, shift=no, llimit=INDEF,\n",
    "ulimit=INDEF, ylevel=0.1, peak=yes, bkg=yes, r_grow=0., avglimits=no,\n",
    "t_nsum=10, t_step=3, t_nlost=3, t_function=\"legendre\", t_order=4,\n",
    "t_sample=\"*\", t_naverage=1, t_niterate=10, t_low_reject=3., t_high_rejec=3.,\n",
    "t_grow=0., background=\"none\", skybox=1, weights=\"none\", pfit=\"fit1d\",\n",
    "clean=no, saturation=INDEF, readnoise=\"5.\", gain=\"0.26\", lsigma=4., usigma=4.,\n",
    "nsubaps=1)\\n\"\"\")\n",
    "        group_num += 1\n",
    "\n",
    "    for comp_filename, files in comp_files.items():\n",
    "        with open(os.path.join(directory_path, comp_filename), 'w') as comp_file:\n",
    "            for file in files:\n",
    "                comp_file.write(f\"{file}\\n\")\n",
    "        print(f\"{comp_filename}\")\n",
    "\n",
    "    imcomb_path = os.path.join(directory_path, \"imcomb.cl\")\n",
    "    with open(imcomb_path, 'w') as imcomb_file:\n",
    "        for line in imcomb_lines:\n",
    "            imcomb_file.write(f\"{line}\\n\")\n",
    "    print(f\"imcomb.cl\")\n",
    "\n",
    "    apall_comp_path = os.path.join(directory_path, \"apall_comp.cl\")\n",
    "    with open(apall_comp_path, 'w') as apall_comp_file:\n",
    "        for line in apall_lines:\n",
    "            apall_comp_file.write(f\"{line}\\n\")\n",
    "    print(f\"apall_comp.cl\")\n",
    "\n",
    "create_comp_and_imcomb_files(directory_path)\n",
    "\n",
    "# Создание и запись файла ut.cl\n",
    "def extract_time(file_name):\n",
    "    match = re.match(r'^\\d{8}-(\\d{6})-.*-(\\d+)s-\\d+.fit$', file_name)\n",
    "    if match:\n",
    "        time_str = match.group(1)\n",
    "        start_time = datetime.strptime(time_str, '%H%M%S')\n",
    "        return start_time\n",
    "    return None\n",
    "\n",
    "def create_ut_file(directory_path, observation_date):\n",
    "    objects = defaultdict(list)\n",
    "    normal_objects = defaultdict(list)\n",
    "\n",
    "    # Собрать времена для каждого файла\n",
    "    for file in os.listdir(directory_path):\n",
    "        if file.endswith('.fit'):\n",
    "            match = re.match(r'^\\d{8}-\\d{6}-(.*)-\\d+s-\\d+.fit$', file)\n",
    "            if match:\n",
    "                object_name = match.group(1)\n",
    "                if object_name != \"THAR\":\n",
    "                    start_time = extract_time(file)\n",
    "                    if start_time:\n",
    "                        objects[object_name].append(start_time)\n",
    "                        status = ha_saturation_status.get(object_name, {'has_saturated': False})\n",
    "                        if not status['has_saturated']:\n",
    "                            normal_objects[object_name].append(start_time)\n",
    "                        elif object_name in ha_saturation_status and file in ha_saturation_status[object_name]['normal_exposures']:\n",
    "                            normal_objects[object_name].append(start_time)\n",
    "\n",
    "    # Вычислить среднее время для каждого объекта\n",
    "    object_average_times = {}\n",
    "    for object_name, times in objects.items():\n",
    "        total_time = sum((t - datetime(1970, 1, 1)).total_seconds() for t in times)\n",
    "        average_time_seconds = total_time / len(times)\n",
    "        average_time = datetime(1970, 1, 1) + timedelta(seconds=average_time_seconds)\n",
    "        object_average_times[object_name] = average_time\n",
    "\n",
    "    # Вычислить среднее время для нормальных экспозиций\n",
    "    normal_average_times = {}\n",
    "    for object_name, times in normal_objects.items():\n",
    "        total_time = sum((t - datetime(1970, 1, 1)).total_seconds() for t in times)\n",
    "        average_time_seconds = total_time / len(times)\n",
    "        average_time = datetime(1970, 1, 1) + timedelta(seconds=average_time_seconds)\n",
    "        normal_average_times[object_name] = average_time\n",
    "\n",
    "    sorted_objects = sorted(object_average_times.items(), key=lambda x: x[1])\n",
    "\n",
    "    # Запись данных в ut.cl\n",
    "    ut_path = os.path.join(directory_path, \"ut.cl\")\n",
    "    with open(ut_path, 'w') as ut_file:\n",
    "        for object_name, avg_time in sorted_objects:\n",
    "            avg_time_str = avg_time.strftime('%H:%M')\n",
    "            status = ha_saturation_status.get(object_name, {'has_saturated': False})\n",
    "            if status['has_saturated']:\n",
    "                ut_file.write(f\"hedit\\t{object_name}_{observation_date}lo_nf\\tUT\\t{avg_time_str}\\n\")\n",
    "                if object_name in normal_average_times:\n",
    "                    normal_avg_time_str = normal_average_times[object_name].strftime('%H:%M')\n",
    "                    ut_file.write(f\"hedit\\t{object_name}_{observation_date}sh_nf\\tUT\\t{normal_avg_time_str}\\n\")\n",
    "            else:\n",
    "                ut_file.write(f\"hedit\\t{object_name}_{observation_date}nf\\tUT\\t{avg_time_str}\\n\")\n",
    "    print(\"ut.cl\")\n",
    "\n",
    "create_ut_file(directory_path, observation_date)\n",
    "\n",
    "# Создание и запись файла thar.cl\n",
    "def create_thar_file(directory_path, observation_date):\n",
    "    ut_path = os.path.join(directory_path, \"ut.cl\")\n",
    "    \n",
    "    # Extract object names and average times from ut.cl\n",
    "    object_avg_times = []\n",
    "    with open(ut_path, 'r') as ut_file:\n",
    "        for line in ut_file:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 4:\n",
    "                object_name = parts[1].split('_')[0]\n",
    "                object_avg_times.append(object_name)\n",
    "    \n",
    "    # Track which objects have already been processed for lo and sh\n",
    "    processed_objects = set()\n",
    "\n",
    "    # Create thar.cl file\n",
    "    thar_path = os.path.join(directory_path, \"thar.cl\")\n",
    "    with open(thar_path, 'w') as thar_file:\n",
    "        for i, object_name in enumerate(object_avg_times):\n",
    "            comp_group = (i // 5) + 1\n",
    "            status = ha_saturation_status.get(object_name, {'has_saturated': False})\n",
    "            if status['has_saturated']:\n",
    "                if f\"{object_name}_lo\" not in processed_objects:\n",
    "                    thar_file.write(f\"hedit\\t{object_name}_{observation_date}lo_nf\\tREFSPEC1\\teb{observation_date}-comp{comp_group}-15s-1\\n\")\n",
    "                    processed_objects.add(f\"{object_name}_lo\")\n",
    "                if f\"{object_name}_sh\" not in processed_objects:\n",
    "                    thar_file.write(f\"hedit\\t{object_name}_{observation_date}sh_nf\\tREFSPEC1\\teb{observation_date}-comp{comp_group}-15s-1\\n\")\n",
    "                    processed_objects.add(f\"{object_name}_sh\")\n",
    "            else:\n",
    "                if f\"{object_name}_nf\" not in processed_objects:\n",
    "                    thar_file.write(f\"hedit\\t{object_name}_{observation_date}nf\\tREFSPEC1\\teb{observation_date}-comp{comp_group}-15s-1\\n\")\n",
    "                    processed_objects.add(f\"{object_name}_nf\")\n",
    "    print(\"thar.cl\")\n",
    "\n",
    "create_thar_file(directory_path, observation_date)\n",
    "\n",
    "# Создание и запись файлов obj.nowav и obj.wav\n",
    "def create_obj_files(directory_path, observation_date, objects):\n",
    "    nowav_path = os.path.join(directory_path, \"obj_nowav\")\n",
    "    wav_path = os.path.join(directory_path, \"obj_wav\")\n",
    "    \n",
    "    with open(nowav_path, 'w') as nowav_file, open(wav_path, 'w') as wav_file:\n",
    "        for obj in objects:\n",
    "            status = ha_saturation_status.get(obj, {'has_saturated': False})\n",
    "            if status['has_saturated']:\n",
    "                nowav_file.write(f\"{obj}_{observation_date}lo_nf.fits\\n\")\n",
    "                nowav_file.write(f\"{obj}_{observation_date}sh_nf.fits\\n\")\n",
    "                wav_file.write(f\"{obj}_{observation_date}lo_nfw.fits\\n\")\n",
    "                wav_file.write(f\"{obj}_{observation_date}sh_nfw.fits\\n\")\n",
    "            else:\n",
    "                nowav_file.write(f\"{obj}_{observation_date}nf.fits\\n\")\n",
    "                wav_file.write(f\"{obj}_{observation_date}nfw.fits\\n\")\n",
    "    \n",
    "    print(\"obj.nowav\")\n",
    "    print(\"obj.wav\")\n",
    "\n",
    "create_obj_files(directory_path, observation_date, objects)\n",
    "\n",
    "print(\"Обработка завершена.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b900491-2759-4dd1-8818-0aa0204abf27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
